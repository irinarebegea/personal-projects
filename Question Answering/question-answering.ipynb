{"cells":[{"cell_type":"code","execution_count":82,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-01-11T13:48:40.513493Z","iopub.status.busy":"2024-01-11T13:48:40.512382Z","iopub.status.idle":"2024-01-11T13:48:40.523358Z","shell.execute_reply":"2024-01-11T13:48:40.522272Z","shell.execute_reply.started":"2024-01-11T13:48:40.513437Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/tensorflow2-question-answering/simplified-nq-train.jsonl\n","/kaggle/input/tensorflow2-question-answering/sample_submission.csv\n","/kaggle/input/tensorflow2-question-answering/simplified-nq-test.jsonl\n"]}],"source":["import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"code","execution_count":83,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T13:48:40.525743Z","iopub.status.busy":"2024-01-11T13:48:40.525356Z","iopub.status.idle":"2024-01-11T13:48:40.535260Z","shell.execute_reply":"2024-01-11T13:48:40.534453Z","shell.execute_reply.started":"2024-01-11T13:48:40.525710Z"},"trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd\n","import json\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt\n","import re\n","import gc\n","import seaborn as sns\n","\n","import tensorflow as tf\n","from nltk.corpus import stopwords\n","from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n","\n","from tensorflow.keras.layers import LSTM, Bidirectional, GlobalMaxPooling1D, SpatialDropout1D, Dense, Dropout, Input, concatenate, Conv1D, Activation, Flatten"]},{"cell_type":"code","execution_count":84,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T13:48:40.536574Z","iopub.status.busy":"2024-01-11T13:48:40.536289Z","iopub.status.idle":"2024-01-11T13:48:40.544106Z","shell.execute_reply":"2024-01-11T13:48:40.543335Z","shell.execute_reply.started":"2024-01-11T13:48:40.536549Z"},"trusted":true},"outputs":[],"source":["#path for data files\n","train_path = '../input/tensorflow2-question-answering/simplified-nq-train.jsonl'\n","test_path = '../input/tensorflow2-question-answering/simplified-nq-test.jsonl'"]},{"cell_type":"markdown","metadata":{},"source":["# **Part 1 - identifying correct long answer to a question**"]},{"cell_type":"code","execution_count":85,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T13:48:40.546014Z","iopub.status.busy":"2024-01-11T13:48:40.545715Z","iopub.status.idle":"2024-01-11T13:48:40.553962Z","shell.execute_reply":"2024-01-11T13:48:40.553168Z","shell.execute_reply.started":"2024-01-11T13:48:40.545991Z"},"trusted":true},"outputs":[],"source":["# define training parameters \n","num_train_ques = 2000\n","num_val_ques = 2050\n","sample_rate = 15"]},{"cell_type":"code","execution_count":86,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T13:48:40.555841Z","iopub.status.busy":"2024-01-11T13:48:40.555573Z","iopub.status.idle":"2024-01-11T13:48:40.563309Z","shell.execute_reply":"2024-01-11T13:48:40.562536Z","shell.execute_reply.started":"2024-01-11T13:48:40.555818Z"},"trusted":true},"outputs":[],"source":["def get_question_and_document(line):\n","    question = line['question_text']\n","    text = line['document_text'].split(' ')\n","    annotations = line['annotations'][0]    \n","    return question, text, annotations\n","                \n","def get_long_candidate(i, annotations, candidate):\n","    # check if this candidate is the correct long answer\n","    if i == annotations['long_answer']['candidate_index']:\n","        label = True\n","    else:\n","        label = False\n","\n","    # get place where long answer starts and ends in the document text\n","    long_start = candidate['start_token']\n","    long_end = candidate['end_token']    \n","    return label, long_start, long_end\n","\n","def form_data_row(question, label, text, long_start, long_end):\n","    row = {\n","        'question': question,\n","        'long_answer': ' '.join(text[long_start:long_end]),\n","        'is_long_answer': label,\n","    }    \n","    return row"]},{"cell_type":"code","execution_count":87,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T13:48:40.564736Z","iopub.status.busy":"2024-01-11T13:48:40.564344Z","iopub.status.idle":"2024-01-11T13:48:40.575356Z","shell.execute_reply":"2024-01-11T13:48:40.574570Z","shell.execute_reply.started":"2024-01-11T13:48:40.564710Z"},"trusted":true},"outputs":[],"source":["def load_data(file_path, questions_start, questions_end):\n","    rows = []\n","    \n","    with open(file_path) as file:\n","        for i in tqdm(range(questions_start, questions_end)):\n","            line = file.readline()\n","            line = json.loads(line)\n","            question, text, annotations = get_question_and_document(line)\n","\n","            for i, candidate in enumerate(line['long_answer_candidates']):\n","                label, long_start, long_end = get_long_candidate(i, annotations, candidate)\n","\n","                if label == True or (i % sample_rate == 0):\n","                    rows.append(\n","                        form_data_row(question, int(label), text, long_start, long_end)\n","                    )        \n","    return pd.DataFrame(rows)"]},{"cell_type":"code","execution_count":88,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T13:48:40.577315Z","iopub.status.busy":"2024-01-11T13:48:40.577077Z","iopub.status.idle":"2024-01-11T13:48:43.200334Z","shell.execute_reply":"2024-01-11T13:48:43.199340Z","shell.execute_reply.started":"2024-01-11T13:48:40.577295Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d13521ed7b548519f4cbceac0470ddb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"303078e94365432380a0139468079ed4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/50 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["train_df = load_data(train_path, 0, num_train_ques)\n","test_df = load_data(train_path, num_train_ques, num_val_ques)"]},{"cell_type":"code","execution_count":89,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T13:48:43.202190Z","iopub.status.busy":"2024-01-11T13:48:43.201898Z","iopub.status.idle":"2024-01-11T13:48:43.212250Z","shell.execute_reply":"2024-01-11T13:48:43.211331Z","shell.execute_reply.started":"2024-01-11T13:48:43.202165Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>long_answer</th>\n","      <th>is_long_answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>which is the most common use of opt-in e-mail ...</td>\n","      <td>&lt;Table&gt; &lt;Tr&gt; &lt;Td&gt; &lt;/Td&gt; &lt;Td&gt; ( hide ) This art...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>which is the most common use of opt-in e-mail ...</td>\n","      <td>&lt;Tr&gt; &lt;Td&gt; &lt;Ul&gt; &lt;Li&gt; Pay - per - click &lt;/Li&gt; &lt;L...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>which is the most common use of opt-in e-mail ...</td>\n","      <td>&lt;P&gt; Email marketing has evolved rapidly alongs...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>which is the most common use of opt-in e-mail ...</td>\n","      <td>&lt;Li&gt; Advertisers can reach substantial numbers...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>which is the most common use of opt-in e-mail ...</td>\n","      <td>&lt;P&gt; A common example of permission marketing i...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            question  \\\n","0  which is the most common use of opt-in e-mail ...   \n","1  which is the most common use of opt-in e-mail ...   \n","2  which is the most common use of opt-in e-mail ...   \n","3  which is the most common use of opt-in e-mail ...   \n","4  which is the most common use of opt-in e-mail ...   \n","\n","                                         long_answer  is_long_answer  \n","0  <Table> <Tr> <Td> </Td> <Td> ( hide ) This art...               0  \n","1  <Tr> <Td> <Ul> <Li> Pay - per - click </Li> <L...               0  \n","2  <P> Email marketing has evolved rapidly alongs...               0  \n","3  <Li> Advertisers can reach substantial numbers...               0  \n","4  <P> A common example of permission marketing i...               1  "]},"execution_count":89,"metadata":{},"output_type":"execute_result"}],"source":["train_df.head(5)"]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T13:48:43.213740Z","iopub.status.busy":"2024-01-11T13:48:43.213391Z","iopub.status.idle":"2024-01-11T13:48:43.226029Z","shell.execute_reply":"2024-01-11T13:48:43.225088Z","shell.execute_reply.started":"2024-01-11T13:48:43.213713Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>long_answer</th>\n","      <th>is_long_answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>which is the most common use of opt-in e-mail ...</td>\n","      <td>&lt;Table&gt; &lt;Tr&gt; &lt;Td&gt; &lt;/Td&gt; &lt;Td&gt; ( hide ) This art...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>which is the most common use of opt-in e-mail ...</td>\n","      <td>&lt;Tr&gt; &lt;Td&gt; &lt;Ul&gt; &lt;Li&gt; Pay - per - click &lt;/Li&gt; &lt;L...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>which is the most common use of opt-in e-mail ...</td>\n","      <td>&lt;P&gt; Email marketing has evolved rapidly alongs...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>which is the most common use of opt-in e-mail ...</td>\n","      <td>&lt;Li&gt; Advertisers can reach substantial numbers...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>which is the most common use of opt-in e-mail ...</td>\n","      <td>&lt;P&gt; A common example of permission marketing i...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            question  \\\n","0  which is the most common use of opt-in e-mail ...   \n","1  which is the most common use of opt-in e-mail ...   \n","2  which is the most common use of opt-in e-mail ...   \n","3  which is the most common use of opt-in e-mail ...   \n","4  which is the most common use of opt-in e-mail ...   \n","\n","                                         long_answer  is_long_answer  \n","0  <Table> <Tr> <Td> </Td> <Td> ( hide ) This art...               0  \n","1  <Tr> <Td> <Ul> <Li> Pay - per - click </Li> <L...               0  \n","2  <P> Email marketing has evolved rapidly alongs...               0  \n","3  <Li> Advertisers can reach substantial numbers...               0  \n","4  <P> A common example of permission marketing i...               1  "]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["test_df.head(5)"]},{"cell_type":"markdown","metadata":{},"source":["# **Pre-processing texts**"]},{"cell_type":"code","execution_count":91,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T13:48:43.228525Z","iopub.status.busy":"2024-01-11T13:48:43.228196Z","iopub.status.idle":"2024-01-11T13:48:43.237324Z","shell.execute_reply":"2024-01-11T13:48:43.236256Z","shell.execute_reply.started":"2024-01-11T13:48:43.228473Z"},"trusted":true},"outputs":[],"source":["#cleaning texts by removing stopwords \n","def remove_stopwords(sentence):\n","    words = sentence.split()\n","    words = [word for word in words if word not in stopwords.words('english')]\n","    return ' '.join(words)\n","\n","#removing html tags \n","def remove_html(sentence):\n","    html = re.compile(r'<.*?>` `` ')\n","    return html.sub(r'', sentence)\n","\n","#returns the pre-processed dataframe for long answers and questions\n","def preprocessed_df(df):\n","    df['long_answer'] = df['long_answer'].apply(lambda x : remove_html(x))\n","    df['long_answer'] = df['long_answer'].apply(lambda x : remove_stopwords(x))\n","\n","    df['question'] = df['question'].apply(lambda x : remove_html(x))\n","    df['question'] = df['question'].apply(lambda x : remove_stopwords(x))\n","    \n","    return df"]},{"cell_type":"code","execution_count":94,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T13:50:47.391677Z","iopub.status.busy":"2024-01-11T13:50:47.390630Z","iopub.status.idle":"2024-01-11T13:55:15.826219Z","shell.execute_reply":"2024-01-11T13:55:15.825249Z","shell.execute_reply.started":"2024-01-11T13:50:47.391635Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>long_answer</th>\n","      <th>is_long_answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>common use opt-in e-mail marketing</td>\n","      <td>&lt;Table&gt; &lt;Tr&gt; &lt;Td&gt; &lt;/Td&gt; &lt;Td&gt; ( hide ) This art...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>common use opt-in e-mail marketing</td>\n","      <td>&lt;Tr&gt; &lt;Td&gt; &lt;Ul&gt; &lt;Li&gt; Pay - per - click &lt;/Li&gt; &lt;L...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>common use opt-in e-mail marketing</td>\n","      <td>&lt;P&gt; Email marketing evolved rapidly alongside ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>common use opt-in e-mail marketing</td>\n","      <td>&lt;Li&gt; Advertisers reach substantial numbers ema...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>common use opt-in e-mail marketing</td>\n","      <td>&lt;P&gt; A common example permission marketing news...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                             question  \\\n","0  common use opt-in e-mail marketing   \n","1  common use opt-in e-mail marketing   \n","2  common use opt-in e-mail marketing   \n","3  common use opt-in e-mail marketing   \n","4  common use opt-in e-mail marketing   \n","\n","                                         long_answer  is_long_answer  \n","0  <Table> <Tr> <Td> </Td> <Td> ( hide ) This art...               0  \n","1  <Tr> <Td> <Ul> <Li> Pay - per - click </Li> <L...               0  \n","2  <P> Email marketing evolved rapidly alongside ...               0  \n","3  <Li> Advertisers reach substantial numbers ema...               0  \n","4  <P> A common example permission marketing news...               1  "]},"execution_count":94,"metadata":{},"output_type":"execute_result"}],"source":["train_df = preprocessed_df(train_df)\n","test_df = preprocessed_df(test_df)\n","train_df.head(5)"]},{"cell_type":"markdown","metadata":{},"source":["# ***Pre-processing***"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.382869Z","iopub.status.idle":"2024-01-11T13:50:01.383476Z","shell.execute_reply":"2024-01-11T13:50:01.383298Z","shell.execute_reply.started":"2024-01-11T13:50:01.383275Z"},"trusted":true},"outputs":[],"source":["train_df.head(10)['long_answer']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.384875Z","iopub.status.idle":"2024-01-11T13:50:01.385235Z","shell.execute_reply":"2024-01-11T13:50:01.385085Z","shell.execute_reply.started":"2024-01-11T13:50:01.385067Z"},"trusted":true},"outputs":[],"source":["# Shuffle training dataframe\n","\n","train_df = train_df.sample(frac=1, random_state=42)\n","train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.387087Z","iopub.status.idle":"2024-01-11T13:50:01.387426Z","shell.execute_reply":"2024-01-11T13:50:01.387278Z","shell.execute_reply.started":"2024-01-11T13:50:01.387262Z"},"trusted":true},"outputs":[],"source":["# How many examples of each class?\n","train_df.is_long_answer.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.388545Z","iopub.status.idle":"2024-01-11T13:50:01.388991Z","shell.execute_reply":"2024-01-11T13:50:01.388776Z","shell.execute_reply.started":"2024-01-11T13:50:01.388755Z"},"trusted":true},"outputs":[],"source":["# Data is unbalanced, up-sampling\n","\n","from sklearn.utils import resample\n","#create two different dataframe of majority and minority class \n","df_majority = train_df[(train_df['is_long_answer']==0)] \n","df_minority = train_df[(train_df['is_long_answer']==1)] \n","# upsample minority class\n","df_minority_upsampled = resample(df_minority, \n","                                 replace=True,    # sample with replacement\n","                                 n_samples= int((len(train_df) * 50) / 100), # to match majority class\n","                                 random_state=42)  # reproducible results\n","# Combine majority class with upsampled minority class\n","train_df = pd.concat([df_minority_upsampled, df_majority])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.390857Z","iopub.status.idle":"2024-01-11T13:50:01.391210Z","shell.execute_reply":"2024-01-11T13:50:01.391050Z","shell.execute_reply.started":"2024-01-11T13:50:01.391034Z"},"trusted":true},"outputs":[],"source":["train_df.is_long_answer.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.392008Z","iopub.status.idle":"2024-01-11T13:50:01.392311Z","shell.execute_reply":"2024-01-11T13:50:01.392173Z","shell.execute_reply.started":"2024-01-11T13:50:01.392159Z"},"trusted":true},"outputs":[],"source":["test_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.393142Z","iopub.status.idle":"2024-01-11T13:50:01.393445Z","shell.execute_reply":"2024-01-11T13:50:01.393308Z","shell.execute_reply.started":"2024-01-11T13:50:01.393294Z"},"trusted":true},"outputs":[],"source":["print(f\"Total training samples: {len(train_df)}\")\n","print(f\"Total test samples: {len(test_df)}\")\n","print(f\"Total samples: {len(train_df) + len(test_df)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.395342Z","iopub.status.idle":"2024-01-11T13:50:01.395811Z","shell.execute_reply":"2024-01-11T13:50:01.395599Z","shell.execute_reply.started":"2024-01-11T13:50:01.395578Z"},"trusted":true},"outputs":[],"source":["# Visualize random training examples\n","\n","import random\n","random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n","for row in train_df[[\"question\", \"long_answer\", \"is_long_answer\"]][random_index:random_index+5].itertuples():\n","  _, q, la, ila = row\n","  print(f\"Target: {ila}\", \"(true label)\" if ila > 0 else \"(not true label)\")\n","  print(f\"Question:\\n{q}\\n\")\n","  print(f\"Long answer:\\n{la}\\n\")\n","  print(\"---\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.397277Z","iopub.status.idle":"2024-01-11T13:50:01.397746Z","shell.execute_reply":"2024-01-11T13:50:01.397531Z","shell.execute_reply.started":"2024-01-11T13:50:01.397509Z"},"trusted":true},"outputs":[],"source":["# Splitting into training and validation sets\n","\n","from sklearn.model_selection import train_test_split\n","\n","# Use train_test_split to split training data into training and validation sets\n","train_data, val_data, train_labels, val_labels = train_test_split(\n","    train_df[[\"question\", \"long_answer\"]],  # Select relevant columns\n","    train_df[\"is_long_answer\"],\n","    test_size=0.1,\n","    random_state=42\n",")\n","\n","len(train_data), len(val_data), len(train_labels), len(val_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.398931Z","iopub.status.idle":"2024-01-11T13:50:01.399382Z","shell.execute_reply":"2024-01-11T13:50:01.399179Z","shell.execute_reply.started":"2024-01-11T13:50:01.399159Z"},"trusted":true},"outputs":[],"source":["val_labels.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.400932Z","iopub.status.idle":"2024-01-11T13:50:01.401371Z","shell.execute_reply":"2024-01-11T13:50:01.401167Z","shell.execute_reply.started":"2024-01-11T13:50:01.401146Z"},"trusted":true},"outputs":[],"source":["train_data[:10], train_labels[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.402524Z","iopub.status.idle":"2024-01-11T13:50:01.402957Z","shell.execute_reply":"2024-01-11T13:50:01.402752Z","shell.execute_reply.started":"2024-01-11T13:50:01.402732Z"},"trusted":true},"outputs":[],"source":["train_data"]},{"cell_type":"markdown","metadata":{},"source":["# ***Converting text into numbers***"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.404220Z","iopub.status.idle":"2024-01-11T13:50:01.404570Z","shell.execute_reply":"2024-01-11T13:50:01.404391Z","shell.execute_reply.started":"2024-01-11T13:50:01.404376Z"},"trusted":true},"outputs":[],"source":["# Text vectorization (tokenization)\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import TextVectorization # after TensorFlow 2.6\n","\n","# Before TensorFlow 2.6\n","# from tensorflow.keras.layers.experimental.preprocessing import TextVectorization \n","# Note: in TensorFlow 2.6+, you no longer need \"layers.experimental.preprocessing\"\n","# you can use: \"tf.keras.layers.TextVectorization\", see https://github.com/tensorflow/tensorflow/releases/tag/v2.6.0 for more\n","\n","# Use the default TextVectorization variables\n","text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n","                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n","                                    split=\"whitespace\", # how to split tokens\n","                                    ngrams=None, # create groups of n-words?\n","                                    output_mode=\"int\", # how to map tokens to numbers\n","                                    output_sequence_length=None) # how long should the output sequence of tokens be?\n","                                    # pad_to_max_tokens=True) # Not valid if using max_tokens=None"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.405549Z","iopub.status.idle":"2024-01-11T13:50:01.405859Z","shell.execute_reply":"2024-01-11T13:50:01.405719Z","shell.execute_reply.started":"2024-01-11T13:50:01.405704Z"},"trusted":true},"outputs":[],"source":["# Find average number of tokens (words) in long answers\n","round(sum([len(i.split()) for i in train_data.long_answer])/len(train_data.long_answer))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.406794Z","iopub.status.idle":"2024-01-11T13:50:01.407124Z","shell.execute_reply":"2024-01-11T13:50:01.406977Z","shell.execute_reply.started":"2024-01-11T13:50:01.406962Z"},"trusted":true},"outputs":[],"source":["# Setup text vectorization with custom variables\n","max_vocab_length = 20000 # max number of words to have in our vocabulary; true value ~ 67k\n","max_length = 150 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n","\n","text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n","                                    output_mode=\"int\",\n","                                    output_sequence_length=max_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.408525Z","iopub.status.idle":"2024-01-11T13:50:01.408963Z","shell.execute_reply":"2024-01-11T13:50:01.408759Z","shell.execute_reply.started":"2024-01-11T13:50:01.408738Z"},"trusted":true},"outputs":[],"source":["# Fit the text vectorizer to the training text\n","# Combine 'question' and 'long_answer' into a single column\n","train_sentences = train_df['question'] + ' ' + train_df['long_answer']\n","\n","# Adapt the vectorizer on the training data\n","text_vectorizer.adapt(train_sentences)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.410543Z","iopub.status.idle":"2024-01-11T13:50:01.410879Z","shell.execute_reply":"2024-01-11T13:50:01.410732Z","shell.execute_reply.started":"2024-01-11T13:50:01.410716Z"},"trusted":true},"outputs":[],"source":["# Get the unique words in the vocabulary\n","words_in_vocab = text_vectorizer.get_vocabulary()\n","top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n","bottom_5_words = words_in_vocab[-5:] # least common tokens\n","print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n","print(f\"Top 5 most common words: {top_5_words}\") \n","print(f\"Bottom 5 least common words: {bottom_5_words}\")"]},{"cell_type":"markdown","metadata":{},"source":["# ***Embedding layer***"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.412011Z","iopub.status.idle":"2024-01-11T13:50:01.412397Z","shell.execute_reply":"2024-01-11T13:50:01.412245Z","shell.execute_reply.started":"2024-01-11T13:50:01.412228Z"},"trusted":true},"outputs":[],"source":["tf.random.set_seed(42)\n","from tensorflow.keras import layers\n","\n","embedding_layer = layers.Embedding(input_dim=max_vocab_length, # set input shape\n","                             output_dim=128, # set size of embedding vector\n","                             embeddings_initializer=\"uniform\", # default, intialize randomly\n","                             input_length=max_length, # how long is each input\n","                             name=\"embedding_1\") \n","\n","embedding_layer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.413920Z","iopub.status.idle":"2024-01-11T13:50:01.414419Z","shell.execute_reply":"2024-01-11T13:50:01.414190Z","shell.execute_reply.started":"2024-01-11T13:50:01.414165Z"},"trusted":true},"outputs":[],"source":["# Get a random sentence from training set\n","random_sentence = random.choice(train_data.long_answer)\n","print(f\"Original text:\\n{random_sentence}\\\n","      \\n\\nEmbedded version:\")\n","\n","# Embed the random sentence (turn it into numerical representation)\n","sample_embed = embedding_layer(text_vectorizer([random_sentence]))\n","sample_embed"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.415789Z","iopub.status.idle":"2024-01-11T13:50:01.416097Z","shell.execute_reply":"2024-01-11T13:50:01.415959Z","shell.execute_reply.started":"2024-01-11T13:50:01.415945Z"},"trusted":true},"outputs":[],"source":["# Check out a single token's embedding\n","sample_embed[0][0]"]},{"cell_type":"markdown","metadata":{},"source":["# ***Model definition***"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.417724Z","iopub.status.idle":"2024-01-11T13:50:01.418162Z","shell.execute_reply":"2024-01-11T13:50:01.417957Z","shell.execute_reply.started":"2024-01-11T13:50:01.417937Z"},"trusted":true},"outputs":[],"source":["# question encoding-encodes the question\n","question_input = layers.Input(shape=(1,), dtype=\"string\")\n","question_x = text_vectorizer(question_input) # turn the input text into numbers\n","question_x = embedding_layer(question_x) # create an embedding of the numerized numbers\n","question_x = SpatialDropout1D(0.2)(question_x)\n","question_x = Bidirectional(LSTM(100, return_sequences=True))(question_x)\n","question_x = GlobalMaxPooling1D()(question_x) # outputs an encoded array representing the question\n","\n","# answer encoding-encodes the answer\n","answer_input = Input(shape=(1,), dtype=\"string\")\n","answer_x = text_vectorizer(answer_input)\n","answer_x = embedding_layer(answer_x)\n","answer_x = SpatialDropout1D(0.2)(answer_x)\n","answer_x = Bidirectional(LSTM(150, return_sequences=True))(answer_x)\n","answer_x = GlobalMaxPooling1D()(answer_x) #outputs an encoded array representing the answer\n","\n","# classification\n","combined_x = concatenate([question_x, answer_x])\n","combined_x = Dense(300, activation='relu')(combined_x)\n","combined_x = Dropout(0.5)(combined_x)\n","combined_x = Dense(300, activation='relu')(combined_x)\n","combined_x = Dropout(0.5)(combined_x)\n","model_output = Dense(1, activation='sigmoid')(combined_x) # probability how close the potential answer is to the true answer to the question.\n","\n","# defining model by combining above three parts\n","model = tf.keras.models.Model(inputs=[answer_input, question_input], outputs=model_output)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.419717Z","iopub.status.idle":"2024-01-11T13:50:01.420146Z","shell.execute_reply":"2024-01-11T13:50:01.419944Z","shell.execute_reply.started":"2024-01-11T13:50:01.419923Z"},"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.425135Z","iopub.status.idle":"2024-01-11T13:50:01.425478Z","shell.execute_reply":"2024-01-11T13:50:01.425332Z","shell.execute_reply.started":"2024-01-11T13:50:01.425316Z"},"trusted":true},"outputs":[],"source":["model.compile(\n","    loss='binary_crossentropy', \n","    optimizer='adam',\n","    metrics=['BinaryAccuracy', 'Recall', 'Precision'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.426807Z","iopub.status.idle":"2024-01-11T13:50:01.427115Z","shell.execute_reply":"2024-01-11T13:50:01.426977Z","shell.execute_reply.started":"2024-01-11T13:50:01.426963Z"},"trusted":true},"outputs":[],"source":["#define callbacks - to avoid plateauing & achieve early stopping\n","callbacks = [\n","    tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=2, verbose=1),\n","    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5, verbose=1),]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.429097Z","iopub.status.idle":"2024-01-11T13:50:01.429429Z","shell.execute_reply":"2024-01-11T13:50:01.429281Z","shell.execute_reply.started":"2024-01-11T13:50:01.429266Z"},"trusted":true},"outputs":[],"source":["# define model parameters\n","epochs = 10\n","batch_size = 128\n","# class_weights = {0: 0.5, 1: 5.}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.430612Z","iopub.status.idle":"2024-01-11T13:50:01.430919Z","shell.execute_reply":"2024-01-11T13:50:01.430782Z","shell.execute_reply.started":"2024-01-11T13:50:01.430767Z"},"trusted":true},"outputs":[],"source":["history = model.fit(\n","    x=[train_data['long_answer'], train_data['question']],\n","    y=train_labels,\n","    validation_data=([val_data['long_answer'], val_data['question']], val_labels),\n","    epochs=epochs,\n","    batch_size=batch_size,\n","    callbacks=callbacks,\n","    shuffle=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.432659Z","iopub.status.idle":"2024-01-11T13:50:01.433112Z","shell.execute_reply":"2024-01-11T13:50:01.432893Z","shell.execute_reply.started":"2024-01-11T13:50:01.432872Z"},"trusted":true},"outputs":[],"source":["#save model\n","model.save('long_model_no_pretraining')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.434277Z","iopub.status.idle":"2024-01-11T13:50:01.434743Z","shell.execute_reply":"2024-01-11T13:50:01.434530Z","shell.execute_reply.started":"2024-01-11T13:50:01.434507Z"},"trusted":true},"outputs":[],"source":["model.evaluate([val_data['long_answer'], val_data['question']], val_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.436058Z","iopub.status.idle":"2024-01-11T13:50:01.436533Z","shell.execute_reply":"2024-01-11T13:50:01.436307Z","shell.execute_reply.started":"2024-01-11T13:50:01.436281Z"},"trusted":true},"outputs":[],"source":["model_prediction_probs = model.predict([test_df['long_answer'], test_df['question']])\n","model_prediction_probs[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.438160Z","iopub.status.idle":"2024-01-11T13:50:01.438475Z","shell.execute_reply":"2024-01-11T13:50:01.438330Z","shell.execute_reply.started":"2024-01-11T13:50:01.438316Z"},"trusted":true},"outputs":[],"source":["model_prediction_probs = tf.squeeze(tf.round(model_prediction_probs)) # squeeze removes single dimensions\n","model_prediction_probs[:20]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.439390Z","iopub.status.idle":"2024-01-11T13:50:01.439730Z","shell.execute_reply":"2024-01-11T13:50:01.439584Z","shell.execute_reply.started":"2024-01-11T13:50:01.439569Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","def calculate_results(y_true, y_pred):\n","  \"\"\"\n","  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n","\n","  Args:\n","  -----\n","  y_true = true labels in the form of a 1D array\n","  y_pred = predicted labels in the form of a 1D array\n","\n","  Returns a dictionary of accuracy, precision, recall, f1-score.\n","  \"\"\"\n","  # Calculate model accuracy\n","  model_accuracy = accuracy_score(y_true, y_pred) * 100\n","  # Calculate model precision, recall and f1 score using \"weighted\" average\n","  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n","  model_results = {\"accuracy\": model_accuracy,\n","                  \"precision\": model_precision,\n","                  \"recall\": model_recall,\n","                  \"f1\": model_f1}\n","  return model_results"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.441435Z","iopub.status.idle":"2024-01-11T13:50:01.441801Z","shell.execute_reply":"2024-01-11T13:50:01.441648Z","shell.execute_reply.started":"2024-01-11T13:50:01.441632Z"},"trusted":true},"outputs":[],"source":["model_1_results = calculate_results(y_true=test_df['is_long_answer'], \n","                                    y_pred=model_prediction_probs)\n","model_1_results"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.443228Z","iopub.status.idle":"2024-01-11T13:50:01.443579Z","shell.execute_reply":"2024-01-11T13:50:01.443396Z","shell.execute_reply.started":"2024-01-11T13:50:01.443382Z"},"trusted":true},"outputs":[],"source":["#part 2\n","\n","#filter records where short answers exist\n","def get_short_answer(annotations, long_start, long_end):\n","    if len(annotations['short_answers']) > 0:\n","        short_start = annotations['short_answers'][0]['start_token']\n","        short_end = annotations['short_answers'][0]['end_token']        \n","        short_start = short_start - long_start\n","        short_end = short_end - long_start        \n","        return short_start, short_end\n","    else:\n","        return 0, 0\n","    \n","def form_short_data_row(question, text, long_start, long_end, short_start, short_end):\n","    long_answer = ' '.join(text[long_start:long_end])\n","    short_answer = ' '.join(long_answer.split(' ')[short_start:short_end])\n","    row = {\n","        'question': question,\n","        'long_answer': long_answer,\n","        'short_answer': short_answer,\n","        'short_start': short_start,\n","        'short_end': short_end\n","    }    \n","    return row"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.444719Z","iopub.status.idle":"2024-01-11T13:50:01.445040Z","shell.execute_reply":"2024-01-11T13:50:01.444897Z","shell.execute_reply.started":"2024-01-11T13:50:01.444881Z"},"trusted":true},"outputs":[],"source":["#loading short answers\n","def load_short_data(file_path, questions_start, questions_end):\n","    rows = []    \n","    with open(file_path) as file:\n","\n","        for i in tqdm(range(questions_start, questions_end)):\n","            line = file.readline()\n","            line = json.loads(line)\n","            question, text, annotations = get_question_and_document(line)\n","            for i, candidate in enumerate(line['long_answer_candidates']):\n","                label, long_start, long_end = get_long_candidate(i, annotations, candidate)\n","\n","                if label == True:\n","                    short_start, short_end = get_short_answer(annotations, long_start, long_end)\n","                    \n","                    rows.append(\n","                        form_short_data_row(question, text, long_start, long_end, short_start, short_end)\n","                    )\n","    return pd.DataFrame(rows)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.446018Z","iopub.status.idle":"2024-01-11T13:50:01.446319Z","shell.execute_reply":"2024-01-11T13:50:01.446181Z","shell.execute_reply.started":"2024-01-11T13:50:01.446168Z"},"trusted":true},"outputs":[],"source":["train_short_data = load_short_data(train_path, 0 , num_train_ques)\n","test_short_data = load_short_data(train_path, num_train_ques, num_val_ques)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.447812Z","iopub.status.idle":"2024-01-11T13:50:01.448147Z","shell.execute_reply":"2024-01-11T13:50:01.448001Z","shell.execute_reply.started":"2024-01-11T13:50:01.447985Z"},"trusted":true},"outputs":[],"source":["train_short_data.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.449672Z","iopub.status.idle":"2024-01-11T13:50:01.450013Z","shell.execute_reply":"2024-01-11T13:50:01.449861Z","shell.execute_reply.started":"2024-01-11T13:50:01.449846Z"},"trusted":true},"outputs":[],"source":["#check count values in each column\n","def count_values_in_column(data,feature):\n","    total=data.loc[:,feature].value_counts(dropna=False)\n","    percentage=round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100,2)\n","    return pd.concat([total,percentage],axis=1,keys=['Total','Percentage'])\n","\n","count_values_in_column(train_short_data, 'short_answer')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.451123Z","iopub.status.idle":"2024-01-11T13:50:01.451424Z","shell.execute_reply":"2024-01-11T13:50:01.451286Z","shell.execute_reply.started":"2024-01-11T13:50:01.451272Z"},"trusted":true},"outputs":[],"source":["#tokenizing\n","#tokenization params\n","filters = '!\"''#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n","lower_case = True\n","max_len = 500 #max lenght of a sentence input in to the model\n","\n","#assigning numeric index to each unique work\n","def define_tokenizer(series):\n","    sentences = pd.concat(series)    \n","    tokenizer = tf.keras.preprocessing.text.Tokenizer(lower=lower_case,filters=filters  )\n","    tokenizer.fit_on_texts(sentences)\n","    return tokenizer\n","\n","#encoding\n","def encode(sentences, tokenizer):\n","    encoded_sentences = tokenizer.texts_to_sequences(sentences)\n","    encoded_sentences = tf.keras.preprocessing.sequence.pad_sequences(encoded_sentences,\n","                                                                      maxlen=max_len, padding='post')\n","    return encoded_sentences\n","\n","tokenizer = define_tokenizer([train_df.long_answer, train_df.question, test_df.long_answer, test_df.question])\n","\n","train_long_ans = encode(train_short_data['long_answer'].values, tokenizer)\n","train_questions = encode(train_short_data['question'].values, tokenizer)\n","\n","test_long_ans = encode(test_short_data['long_answer'].values, tokenizer)\n","test_questions = encode(test_short_data['question'].values, tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.452290Z","iopub.status.idle":"2024-01-11T13:50:01.452648Z","shell.execute_reply":"2024-01-11T13:50:01.452471Z","shell.execute_reply.started":"2024-01-11T13:50:01.452456Z"},"trusted":true},"outputs":[],"source":["#define 2 arrays for the start index and another for the end index\n","def form_short_labels(df, sentence_length):\n","    start_labels = np.zeros((len(df), sentence_length))\n","    end_labels = np.zeros((len(df), sentence_length))\n","\n","    #get the token indexes from short_start and short_end columns and assign it to new arrays. encoding with 1\n","    for i in range(len(df)):\n","        start = df.loc[i].short_start\n","        end = df.loc[i].short_end\n","\n","        if start < 500 and end < 500:\n","            start_labels[i, start] = 1\n","            end_labels[i, end] = 1\n","        else:\n","            continue\n","    return start_labels, end_labels\n","\n","train_start_labels, train_end_labels = form_short_labels(train_short_data, max_len)\n","test_start_labels, test_end_labels = form_short_labels(test_short_data, max_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.453735Z","iopub.status.idle":"2024-01-11T13:50:01.454072Z","shell.execute_reply":"2024-01-11T13:50:01.453919Z","shell.execute_reply.started":"2024-01-11T13:50:01.453903Z"},"trusted":true},"outputs":[],"source":["print(train_short_data.loc[10].question)\n","\n","print(train_short_data.loc[10].long_answer)\n","print(train_short_data.loc[10].short_answer)\n","\n","print('Start index: {0}'.format(train_start_labels[10]))\n","print('End index: {0}'.format(train_end_labels[10]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.455374Z","iopub.status.idle":"2024-01-11T13:50:01.455716Z","shell.execute_reply":"2024-01-11T13:50:01.455571Z","shell.execute_reply.started":"2024-01-11T13:50:01.455555Z"},"trusted":true},"outputs":[],"source":["# short answer model parameters\n","short_epochs = 10\n","short_batch_size = 32\n","embed_size_short=200"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.456970Z","iopub.status.idle":"2024-01-11T13:50:01.457295Z","shell.execute_reply":"2024-01-11T13:50:01.457151Z","shell.execute_reply.started":"2024-01-11T13:50:01.457135Z"},"trusted":true},"outputs":[],"source":["#write to matrix after loading from file\n","\n","vocab = train_df.long_answer + train_df.question + test_df.long_answer + test_df.question\n","embedding_dict = {word: i for i, word in enumerate(vocab)}\n","\n","\n","num_words = len(tokenizer.word_index) + 1\n","embedding_matrix = np.zeros((num_words, embed_size_short))\n","\n","for word, i in tokenizer.word_index.items():\n","    if i > num_words:\n","        continue\n","    \n","    emb_vec = embedding_dict.get(word)\n","    \n","    if emb_vec is not None:\n","        embedding_matrix[i] = emb_vec\n","        \n","        \n","# load as tensorflow embedding\n","#define embedding layer for the short model\n","embedding_layer2 = tf.keras.layers.Embedding(\n","    len(tokenizer.word_index) + 1,\n","    embed_size_short,\n","    embeddings_initializer = tf.keras.initializers.Constant(embedding_matrix),\n","    trainable = False\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.458460Z","iopub.status.idle":"2024-01-11T13:50:01.458797Z","shell.execute_reply":"2024-01-11T13:50:01.458657Z","shell.execute_reply.started":"2024-01-11T13:50:01.458642Z"},"trusted":true},"outputs":[],"source":["#encode the question input\n","question_input = Input(shape=(None,))\n","question_x = embedding_layer2(question_input)\n","question_x = SpatialDropout1D(0.2)(question_x)\n","question_x = Bidirectional(LSTM(200, return_sequences=True))(question_x)\n","question_x = Bidirectional(LSTM(100, return_sequences=True))(question_x)\n","\n","#encode the answer input\n","answer_input = Input(shape=(None,))\n","answer_x = embedding_layer2(answer_input)\n","answer_x = SpatialDropout1D(0.2)(answer_x)\n","answer_x = Bidirectional(LSTM(250, return_sequences=True))(answer_x)\n","answer_x = Bidirectional(LSTM(150, return_sequences=True))(answer_x)\n","\n","combined_x = concatenate([question_x, answer_x])\n","\n","#predict start idx of the short answer\n","start_x = Dropout(0.1)(combined_x) \n","start_x = Conv1D(1,1)(start_x)\n","start_x = Flatten()(start_x)\n","start_x = Activation('softmax', name='start_token')(start_x)\n","\n","#predict end idx\n","end_x = Dropout(0.1)(combined_x) \n","end_x = Conv1D(1,1)(end_x)\n","end_x = Flatten()(end_x)\n","end_x = Activation('softmax', name='end_token')(end_x)\n","\n","short_model = tf.keras.models.Model(inputs=[answer_input, question_input], outputs=[start_x, end_x])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.459896Z","iopub.status.idle":"2024-01-11T13:50:01.460242Z","shell.execute_reply":"2024-01-11T13:50:01.460087Z","shell.execute_reply.started":"2024-01-11T13:50:01.460072Z"},"trusted":true},"outputs":[],"source":["short_model.compile(\n","    loss='categorical_crossentropy', \n","    optimizer='adam',\n","    metrics=['categorical_accuracy', 'Recall', 'Precision'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.462116Z","iopub.status.idle":"2024-01-11T13:50:01.462578Z","shell.execute_reply":"2024-01-11T13:50:01.462352Z","shell.execute_reply.started":"2024-01-11T13:50:01.462331Z"},"trusted":true},"outputs":[],"source":["short_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.463733Z","iopub.status.idle":"2024-01-11T13:50:01.464222Z","shell.execute_reply":"2024-01-11T13:50:01.463973Z","shell.execute_reply.started":"2024-01-11T13:50:01.463944Z"},"trusted":true},"outputs":[],"source":["# define callbacks for the short model\n","#inreased patience or number of epochs with no improvement after which training will be stopped.\n","callbacks = [\n","    tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=4, verbose=1),\n","    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5, verbose=1),]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.469847Z","iopub.status.idle":"2024-01-11T13:50:01.470213Z","shell.execute_reply":"2024-01-11T13:50:01.470065Z","shell.execute_reply.started":"2024-01-11T13:50:01.470049Z"},"trusted":true},"outputs":[],"source":["history = short_model.fit(\n","    x = [train_long_ans, train_questions], \n","    y = [train_start_labels, train_end_labels],epochs = short_epochs, callbacks = callbacks,\n","    validation_data = ([test_long_ans, test_questions], [test_start_labels, test_end_labels]),\n","    batch_size = short_batch_size,  shuffle = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.471357Z","iopub.status.idle":"2024-01-11T13:50:01.471700Z","shell.execute_reply":"2024-01-11T13:50:01.471553Z","shell.execute_reply.started":"2024-01-11T13:50:01.471537Z"},"trusted":true},"outputs":[],"source":["short_model.save('short_model_no_pretraining')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.472696Z","iopub.status.idle":"2024-01-11T13:50:01.473025Z","shell.execute_reply":"2024-01-11T13:50:01.472875Z","shell.execute_reply.started":"2024-01-11T13:50:01.472859Z"},"trusted":true},"outputs":[],"source":["print('Epoch: {0}'.format(len(history.history['loss'])))\n","print('Loss: {0}'.format(history.history['loss'][-1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.474389Z","iopub.status.idle":"2024-01-11T13:50:01.474745Z","shell.execute_reply":"2024-01-11T13:50:01.474598Z","shell.execute_reply.started":"2024-01-11T13:50:01.474583Z"},"trusted":true},"outputs":[],"source":["print('Training final results')\n","\n","accuracy = history.history['start_token_categorical_accuracy'][-1]\n","recall = history.history['start_token_recall'][-1]\n","precision = history.history['start_token_precision'][-1]\n","\n","print('--------------------------------------------------')\n","print('Start token accuracy: {0}'.format(accuracy))\n","print('Start token recall: {0}'.format(recall))\n","print('Start token precision: {0}'.format(precision))\n","print('Start token F1 score: {0:.4f}'.format(2 * (precision * recall) / (precision + recall)))\n","\n","print('--------------------------------------------------')\n","\n","accuracy = history.history['end_token_categorical_accuracy'][-1]\n","recall = history.history['end_token_recall_1'][-1]\n","precision = history.history['end_token_precision_1'][-1]\n","\n","print('End token accuracy: {0}'.format(accuracy))\n","print('End token recall: {0}'.format(recall))\n","print('End token precision: {0}'.format(precision))\n","print('End token F1 score: {0:.4f}'.format(2 * (precision * recall) / (precision + recall)))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:50:01.475851Z","iopub.status.idle":"2024-01-11T13:50:01.476178Z","shell.execute_reply":"2024-01-11T13:50:01.476034Z","shell.execute_reply.started":"2024-01-11T13:50:01.476018Z"},"trusted":true},"outputs":[],"source":["print('Validation final results')\n","print('--------------------------------------------------')\n","\n","accuracy = history.history['val_start_token_categorical_accuracy'][-1]\n","recall = history.history['val_start_token_recall'][-1]\n","precision = history.history['val_start_token_precision'][-1]\n","\n","print('Start token accuracy: {0}'.format(accuracy))\n","print('Start token recall: {0}'.format(recall))\n","print('Start token precision: {0}'.format(precision))\n","print('Start token F1 score: {0:.4f}'.format( 2 * (precision * recall) / (precision + recall)))\n","\n","print('--------------------------------------------------')\n","\n","accuracy = history.history['val_end_token_categorical_accuracy'][-1]\n","recall = history.history['val_end_token_recall_1'][-1]\n","precision = history.history['val_end_token_precision_1'][-1]\n","\n","print('End token accuracy: {0}'.format(accuracy))\n","print('End token recall: {0}'.format(recall))\n","print('End token precision: {0}'.format(precision))\n","print('End token F1 score: {0:.4f}'.format(2 * (precision * recall) / (precision + recall)))"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":788719,"sourceId":12863,"sourceType":"competition"}],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
